{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c4bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## AFDB preprocessing ; preprocess each patients ECG\n",
    "\"\"\"\n",
    "convert each AFDB record into fixed length labeled windows for training\n",
    "Each per record .npz file is saved with:\n",
    "    X: per window z scored ECG wave transform [num_windows,win_len]\n",
    "    y: window label (0 = not AF, 1 = AF)\n",
    "    rr_feat: RR/HRV features per windwo [num_windows:10]\n",
    "    rr_valid: if the rr freatures are valid for that window (t/f)\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb  #record I/O\n",
    "from wfdb import processing  # resampling + signal helpers\n",
    "\n",
    "# bandpass filtering\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "\n",
    "DATA_DIR = Path(\"../data/raw/afdb\")    \n",
    "OUT_DIR  = Path(\"../artifacts/afdb_npz\") \n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "SUMMARY_CSV = OUT_DIR / \"summary.csv\"   #output summary table path\n",
    "\n",
    "LEAD_IDX = 0 #the first channel index for AFDB\n",
    "TARGET_FS = None \n",
    "WIN_SEC = 10 #10s windows of ecg\n",
    "STRIDE_SEC = 5 #each widnow\n",
    "AF_THRESHOLD = 0.2 #if more than 20% of the window overlaps an AF, label it AF\n",
    "LOW_HZ = 0.5 #bandpass low cutoff\n",
    "HIGH_HZ = 40.0 #band pass high cutoff ;; to remove noise\n",
    "F_ORDER = 4 #filter order\n",
    "\n",
    "#graphs vars\n",
    "PLOT_EXAMPLES = False\n",
    "# PLOT_K = 3\n",
    "# PLOT_SEED = 0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f5e48cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions::\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "A band pass filter with 0 phase filtering using filtfilt\n",
    "ECG contains very low freq noise (baseline wander) and high freq noise (powerline noise)\n",
    "filtfilt applies filters forward & backwards which cancels phase distortion but doesnt shift any waves in time \n",
    "otherwise that would ruin the incoming signal\n",
    "\"\"\"\n",
    "\n",
    "def bandpass_filter(\n",
    "        #apply bandpass filter with zero phase filtering\n",
    "#removes low and high freq noise, using filtfilt to avoid phase distortion\n",
    "    x: np.ndarray,\n",
    "    fs: float,\n",
    "    low_hz: float = LOW_HZ,\n",
    "    high_hz: float = HIGH_HZ,\n",
    "    order: int = F_ORDER\n",
    ") -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "\n",
    "    if low_hz <= 0:\n",
    "        raise ValueError(\"low_hz must be > 0\")\n",
    "    if high_hz >= fs / 2:\n",
    "        raise ValueError(\"high_hz must be < Nyquist (fs/2)\")\n",
    "    if high_hz <= low_hz:\n",
    "        raise ValueError(\"high_hz must be > low_hz\")\n",
    "\n",
    "    nyq = fs / 2.0\n",
    "    low = low_hz / nyq\n",
    "    high = high_hz / nyq\n",
    "\n",
    "    b, a = butter(order, [low, high], btype=\"bandpass\")\n",
    "    y = filtfilt(b, a, x)\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "\n",
    "# afdb records have headers.. so read them by base name\n",
    "def listafdbrecords(data_dir:Path):\n",
    "    return sorted({p.stem for p in data_dir.glob(\"*.hea\")})\n",
    "\n",
    "\n",
    "## rhythm interval parsing\n",
    "\n",
    "\"\"\"\n",
    "convert rhythm change markers from the WFDB annotations into closed intervals\n",
    " where label 0=Normal, 1=AF.\n",
    "\n",
    "    Uses aux_note strings like:\n",
    "      '(N'    normal\n",
    "      '(AFIB' AF\n",
    "      '(AFL'  AF\n",
    "\n",
    "\"\"\"\n",
    "# since AFDB labels are typically change points and not per sample labels, we convert to intervals\n",
    "#which makes window labeling easier\n",
    "def build_rhythm_intervals_from_aux(ann_samples, aux_notes, N_total_samples: int):\n",
    "    #Build closed rhythm intervals [start, end)\n",
    "    changes = []  # (sample, label)\n",
    "\n",
    "    for s, aux in zip(ann_samples, aux_notes):\n",
    "        if aux is None:\n",
    "            continue\n",
    "\n",
    "        a = aux.strip().upper()\n",
    "        if a.startswith(\"(AF\") or \"AFIB\" in a or \"AFL\" in a:\n",
    "            changes.append((int(s), 1))\n",
    "        elif a.startswith(\"(N\") or a in (\"N\", \"NSR\", \"(NSR\"):\n",
    "            changes.append((int(s), 0))\n",
    "\n",
    "\n",
    "\n",
    "    changes.sort(key=lambda t: t[0])\n",
    "    if not changes:\n",
    "        return []\n",
    "\n",
    "    #fill beginning if first label starts after 0\n",
    "    if changes[0][0] > 0:#assyme rhythm is whatever the first label says\n",
    "        changes = [(0, changes[0][1])] + changes\n",
    "\n",
    "    intervals = []\n",
    "    for i in range(len(changes)):\n",
    "        start = changes[i][0]\n",
    "        label = changes[i][1]\n",
    "        end = changes[i + 1][0] if i + 1 < len(changes) else N_total_samples\n",
    "\n",
    "        if end > start:\n",
    "            intervals.append((start, end, label))\n",
    "\n",
    "    return intervals\n",
    "\n",
    "\n",
    "#num of samples in the intersection of [a0,a1] + [b0,b1)\n",
    "def interval_overlap(a0,a1,b0,b1):\n",
    "    return max(0,min(a1,b1)-max(a0,b0))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Label window as AF (1) if >= threshold \n",
    "\"\"\"\n",
    "def label_window(start,end, rhythm_intervals, af_threshold=0.2):\n",
    "    total = end - start\n",
    "    if total <= 0:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    af_overlap = 0\n",
    "    for r0, r1, lab in rhythm_intervals:\n",
    "        if lab != 1:\n",
    "            continue\n",
    "        af_overlap += interval_overlap(start, end, r0, r1)\n",
    "    return 1 if (af_overlap / total) >= af_threshold else 0\n",
    "\n",
    "\n",
    "def computeAFfromintervals(rhythm_intervals,N_totalsamples):\n",
    "    if not rhythm_intervals:\n",
    "        return np.nan\n",
    "\n",
    "    af_samples = 0\n",
    "    total = 0\n",
    "    for r0, r1, lab in rhythm_intervals:\n",
    "        r0 = max(0, int(r0))\n",
    "        r1 = min(N_totalsamples, int(r1))\n",
    "        if r1 <= r0:\n",
    "            continue\n",
    "        seg_len = r1 - r0\n",
    "        total += seg_len\n",
    "        if lab == 1:\n",
    "            af_samples += seg_len\n",
    "\n",
    "    return (af_samples / total) if total > 0 else np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def plot_randomwindows(Xplot,y,k=3,seed=0,title_prefix=\"\"):\n",
    "\n",
    "#     rng = np.random.default_rng(seed)\n",
    "\n",
    "#     fig, axes = plt.subplots(2, k, figsize=(4 * k, 5), sharex=True, sharey=True)\n",
    "\n",
    "#     for cls in [0, 1]:\n",
    "#         idxs = np.where(y == cls)[0]\n",
    "#         chosen = rng.choice(idxs, size=min(k, len(idxs)), replace=False) if len(idxs) else []\n",
    "\n",
    "#         for j in range(k):\n",
    "#             ax = axes[cls, j]\n",
    "#             if j < len(chosen):\n",
    "#                 i = chosen[j]\n",
    "#                 ax.plot(Xplot[i])\n",
    "#                 ax.set_title(f\"{title_prefix}{'Normal' if cls==0 else 'AF'} (win={i})\")\n",
    "#             else:\n",
    "#                 ax.set_axis_off()\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d65a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rpeak detectin & RR features\n",
    "\n",
    "\n",
    "## this is a fallback if it cant find annotations\n",
    "def detect_rpeaks_simple(x: np.ndarray, fs: float) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "\n",
    "    dx = np.diff(x, prepend=x[0])     # discrete derivative (same length as x)\n",
    "    energy = (np.abs(dx) ** 2)        # energy-like measure\n",
    "\n",
    "    # Min distance between R-peaks: 0.25s => max 240 bpm\n",
    "    min_dist = int(0.25 * fs)\n",
    "\n",
    "    #thresh is 95th percentile\n",
    "    thr = np.percentile(energy, 95)\n",
    "\n",
    "    peaks, _ = find_peaks(energy, distance=min_dist, height=thr)\n",
    "    return peaks.astype(np.int64)\n",
    "\n",
    "\n",
    "\n",
    "##this should be used primarily\n",
    "\"\"\"\n",
    "WFDB annotations are more accurate and the features extracted make more sense if peaks are accurate\n",
    "\"\"\"\n",
    "def get_rpeaks_from_annotations_or_detect(record_path: str, x: np.ndarray, fs: float, ann=None) -> np.ndarray:\n",
    "\n",
    "    if ann is None:\n",
    "        ann = wfdb.rdann(record_path, \"atr\")  \n",
    "\n",
    "    r = None\n",
    "\n",
    "    # remove +'s , theyre non beat markers\n",
    "    if hasattr(ann, \"symbol\") and ann.symbol is not None and len(ann.symbol) == len(ann.sample):\n",
    "        sym = np.asarray(ann.symbol)\n",
    "        sam = np.asarray(ann.sample, dtype=np.int64)\n",
    "\n",
    "\n",
    "        cand = sam[sym != \"+\"]\n",
    "\n",
    "\n",
    "        cand = cand[(cand >= 0) & (cand < len(x))]\n",
    "\n",
    "        ##needs to have enough beats to matter\n",
    "        if len(cand) >= 10:\n",
    "            r = cand\n",
    "\n",
    "    if r is None:\n",
    "        r = detect_rpeaks_simple(x, fs)\n",
    "\n",
    "    return r.astype(np.int64)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Get 10 RR/HRV features from local winow R peaks\n",
    "\n",
    "#returns:\n",
    "    feat (10,) float32\n",
    "    valid: 1.0 if enough peaks to compute, else 0\n",
    "    #some windows can have too few beats ,, need to verify otherwise model can ignore RR features when invalid\n",
    "\"\"\"\n",
    "def rr_features_from_peaks(r_peaks_win: np.ndarray, fs: float):\n",
    "\n",
    "    #Need at least 3 peaks => at least 2 RR intervals\n",
    "    if r_peaks_win is None or len(r_peaks_win) < 3:\n",
    "        return np.zeros(10, dtype=np.float32), 0.0\n",
    "\n",
    "    rr = np.diff(r_peaks_win).astype(np.float32) / float(fs)  #RR in seconds\n",
    "    if len(rr) < 2:\n",
    "        return np.zeros(10, dtype=np.float32), 0.0\n",
    "\n",
    "    drr = np.diff(rr)                  \n",
    "    abs_drr = np.abs(drr)\n",
    "\n",
    "\n",
    "\n",
    "    mean_rr = rr.mean()\n",
    "    sdnn = rr.std()\n",
    "    rmssd = float(np.sqrt(np.mean(drr ** 2))) if len(drr) else 0.0\n",
    "    pnn50 = float(np.mean(abs_drr > 0.05)) if len(abs_drr) else 0.0  #50ms\n",
    "    cv = float(sdnn / (mean_rr + 1e-8))\n",
    "\n",
    "    med_rr = float(np.median(rr))\n",
    "    iqr_rr = float(np.percentile(rr, 75) - np.percentile(rr, 25))\n",
    "    mad_rr = float(np.median(np.abs(rr - med_rr)))\n",
    "\n",
    "    #Turning point ratio: fraction of local extrema in rr series\n",
    "    if len(rr) >= 3:\n",
    "        tp = 0\n",
    "       # for i in range(1, len(rr) - 1):\n",
    "        for i in range(1, len(rr) - 1):\n",
    "            if (rr[i] > rr[i-1] and rr[i] > rr[i+1]) or (rr[i] < rr[i-1] and rr[i] < rr[i+1]):\n",
    "                tp += 1\n",
    "        tpr = float(tp / (len(rr) - 2))\n",
    "    else:\n",
    "        tpr = 0.0\n",
    "\n",
    "    rr_range = float(rr.max() - rr.min())\n",
    "\n",
    "    feat = np.array(\n",
    "        [mean_rr, sdnn, rmssd, pnn50, cv, med_rr, iqr_rr, mad_rr, tpr, rr_range],\n",
    "        dtype=np.float32)\n",
    "\n",
    "    return feat, 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b07e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process a record at a time\n",
    "\"\"\"\n",
    "### STEPS:\n",
    "    load ecg\n",
    "    resample if needed\n",
    "    bandpass filt\n",
    "    load annotations & build rhythm intervals\n",
    "    window the record\n",
    "    label each window \n",
    "    detect r peaks once on the full patient record\n",
    "    slice peaks per window and compute RR features\n",
    "    per window z score,,, normalize window\n",
    "    save .npz \n",
    "\n",
    "\"\"\"\n",
    "## its prolly easier to detect r peaks once on the whole record instead of doing it per window and it could\n",
    "# cause boundary effects since it could sit right at a boundary and then we have multiple windows if the same peak\n",
    "## doing full recrod is more stable, just slice after\n",
    "def process_one_record(record_id: str):\n",
    "    record_path = str(DATA_DIR / record_id) \n",
    "\n",
    "    # ---- Load signal ----\n",
    "    sig, fields = wfdb.rdsamp(record_path)   # sig shape: (N, n_channels)\n",
    "    fs = float(fields[\"fs\"])     #sampling frequency from header\n",
    "    x = sig[:, LEAD_IDX].astype(np.float32)  #pick channel and cast\n",
    "\n",
    "    # resample if needed!!!\n",
    "    if TARGET_FS is not None and float(TARGET_FS) != fs:\n",
    "        #processing.resample_sig returns (y, new_fields)\n",
    "        x, _ = processing.resample_sig(x, fs, TARGET_FS)\n",
    "        x = x.astype(np.float32)\n",
    "        fs = float(TARGET_FS)\n",
    "\n",
    "\n",
    "    #bandpass filt\n",
    "    x = bandpass_filter(x, fs, low_hz=LOW_HZ, high_hz=HIGH_HZ, order=F_ORDER)\n",
    "\n",
    "    N = len(x)\n",
    "\n",
    "    ann = wfdb.rdann(record_path, \"atr\")  # loads .atr annotation stream\n",
    "\n",
    "    # aux_note is where AFDB rhythm labels live\n",
    "    if not hasattr(ann, \"aux_note\") or ann.aux_note is None:\n",
    "        raise RuntimeError(\"Annotation missing aux_note field (needed for rhythm intervals).\")\n",
    "\n",
    "\n",
    "    # build rhythm intervals\n",
    "    rhythm_intervals = build_rhythm_intervals_from_aux(ann.sample, ann.aux_note, N_total_samples=N)\n",
    "    if not rhythm_intervals:\n",
    "        raise RuntimeError(\"No rhythm intervals found in aux_note ;; (cannot label windows)\")\n",
    "\n",
    "\n",
    "    win_len = int(WIN_SEC * fs)\n",
    "    stride  = int(STRIDE_SEC * fs)\n",
    "\n",
    "    if N < win_len:\n",
    "        raise RuntimeError(f\"Signal too short: {N} samples < {win_len} samples (one window).\")\n",
    "\n",
    "    # Start indices for windows: [0, stride, 2*stride, ...] up to last full window\n",
    "    starts = np.arange(0, N - win_len + 1, stride, dtype=np.int64)\n",
    "\n",
    "    #label each window\n",
    "    y = np.array(\n",
    "        [label_window(int(s), int(s + win_len), rhythm_intervals, af_threshold=AF_THRESHOLD) for s in starts],\n",
    "        dtype=np.int64\n",
    "    )\n",
    "\n",
    "    #full record peak detection \n",
    "    rpeaks_all = get_rpeaks_from_annotations_or_detect(record_path, x, fs, ann=ann)\n",
    "\n",
    "\n",
    "    #cal RR features per window by slicing rpeaks\n",
    "    rr_feat_list = []\n",
    "    rr_valid_list = []\n",
    "\n",
    "    for s in starts:\n",
    "        s0 = int(s)\n",
    "        s1 = int(s + win_len)\n",
    "\n",
    "        #Peaks that fall inside the window (record indices)\n",
    "        mask = (rpeaks_all >= s0) & (rpeaks_all < s1)\n",
    "\n",
    "        #Cnvert to window-relative indices (so features dont depend on absolute time)\n",
    "        rpk_win = rpeaks_all[mask] - s0\n",
    "\n",
    "        f, v = rr_features_from_peaks(rpk_win, fs)\n",
    "        rr_feat_list.append(f)\n",
    "        rr_valid_list.append(v)\n",
    "\n",
    "    rr_feat  = np.stack(rr_feat_list).astype(np.float32)        # (num_windows, 10)\n",
    "    rr_valid = np.asarray(rr_valid_list, dtype=np.float32)      # (num_windows,)\n",
    "\n",
    "\n",
    "    #create window tensor ;; faster processing\n",
    "    X = np.stack([x[s:s + win_len] for s in starts]).astype(np.float32)  # (num_windows, win_len)\n",
    "\n",
    "\n",
    "\n",
    "    ### z score norm per window\\\n",
    "    # removes amplitude scale diffs accross patiens/segments\n",
    "    # also stabilizes learning for the network\n",
    "    Xn = (X - X.mean(axis=1, keepdims=True)) / (X.std(axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "\n",
    "\n",
    "    #######\n",
    "    total_windows = int(len(y))\n",
    "    af_windows = int(y.sum())\n",
    "    af_pct_windows = float(y.mean()) if total_windows else np.nan\n",
    "    af_pct_intervals = float(computeAFfromintervals(rhythm_intervals, N))\n",
    "\n",
    " \n",
    "    #save npz\n",
    "    out_path = OUT_DIR / f\"{record_id}_win{WIN_SEC}_stride{STRIDE_SEC}.npz\"\n",
    "\n",
    "    np.savez_compressed(\n",
    "        out_path,\n",
    "        # core learning inputs\n",
    "        X=Xn,                 # normalized windows\n",
    "        y=y,                  # window labels\n",
    "        rr_feat=rr_feat,      # RR features\n",
    "        rr_valid=rr_valid,    # RR validity mask/flag\n",
    "\n",
    "        #metadata for reproducibility\n",
    "        fs=fs,\n",
    "        win_sec=WIN_SEC,\n",
    "        stride_sec=STRIDE_SEC,\n",
    "        record=record_id,\n",
    "        lead_idx=LEAD_IDX,\n",
    "        af_threshold=AF_THRESHOLD,\n",
    "        low_hz=LOW_HZ,\n",
    "        high_hz=HIGH_HZ,\n",
    "        filter_order=F_ORDER,\n",
    "    )\n",
    "\n",
    "    stats = {\n",
    "        \"record\": record_id,\n",
    "        \"fs\": fs,\n",
    "        \"samples\": N,\n",
    "        \"win_len\": win_len,\n",
    "        \"stride\": stride,\n",
    "        \"windows\": total_windows,\n",
    "        \"af_windows\": af_windows,\n",
    "        \"normal_windows\": total_windows - af_windows,\n",
    "        \"af_pct_windows\": af_pct_windows,\n",
    "        \"af_pct_intervals\": af_pct_intervals,\n",
    "        \"npz_path\": str(out_path),\n",
    "        \"has_both_classes\": (len(np.unique(y)) == 2),\n",
    "    }\n",
    "\n",
    "    return stats, Xn, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76c161f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AFDB Preprocessing Pipeline\n",
      "============================================================\n",
      "Data directory:   ../data/raw/afdb\n",
      "Output directory: ../artifacts/afdb_npz\n",
      "Window: 10s | Stride: 5s | AF threshold: 0.2\n",
      "Filter: 0.5-40.0 Hz | order=4\n",
      "============================================================\n",
      "\n",
      "Found 25 records\n",
      "First 10: ['00735', '03665', '04015', '04043', '04048', '04126', '04746', '04908', '04936', '05091']\n",
      "[01/25] 00735  | SKIP: sampto must be greater than sampfrom\n",
      "[02/25] 03665  | SKIP: sampto must be greater than sampfrom\n",
      "[03/25] 04015  | windows=  7363 | AF=    55 (  0.75%) | interval_AF=  0.64% | saved\n",
      "[04/25] 04043  | windows=  7363 | AF=  1685 ( 22.88%) | interval_AF= 21.54% | saved\n",
      "[05/25] 04048  | windows=  7363 | AF=    80 (  1.09%) | interval_AF=  0.98% | saved\n",
      "[06/25] 04126  | windows=  7363 | AF=   284 (  3.86%) | interval_AF=  3.74% | saved\n",
      "[07/25] 04746  | windows=  7363 | AF=  3917 ( 53.20%) | interval_AF= 53.10% | saved\n",
      "[08/25] 04908  | windows=  7363 | AF=   670 (  9.10%) | interval_AF=  9.06% | saved\n",
      "[09/25] 04936  | windows=  7363 | AF=  6035 ( 81.96%) | interval_AF= 81.34% | saved\n",
      "[10/25] 05091  | windows=  7363 | AF=    25 (  0.34%) | interval_AF=  0.24% | saved\n",
      "[11/25] 05121  | windows=  7363 | AF=  4706 ( 63.91%) | interval_AF= 63.65% | saved\n",
      "[12/25] 05261  | windows=  7363 | AF=   109 (  1.48%) | interval_AF=  1.30% | saved\n",
      "[13/25] 06426  | windows=  7363 | AF=  7089 ( 96.28%) | interval_AF= 95.93% | saved\n",
      "[14/25] 06453  | windows=  6659 | AF=    81 (  1.22%) | interval_AF=  1.11% | saved\n",
      "[15/25] 06995  | windows=  7363 | AF=  3476 ( 47.21%) | interval_AF= 47.17% | saved\n",
      "[16/25] 07162  | windows=  7363 | AF=  7363 (100.00%) | interval_AF=100.00% | saved\n",
      "[17/25] 07859  | windows=  7363 | AF=  7363 (100.00%) | interval_AF=100.00% | saved\n",
      "[18/25] 07879  | windows=  7363 | AF=  4443 ( 60.34%) | interval_AF= 60.31% | saved\n",
      "[19/25] 07910  | windows=  7363 | AF=  1274 ( 17.30%) | interval_AF= 17.26% | saved\n",
      "[20/25] 08215  | windows=  7363 | AF=  5944 ( 80.73%) | interval_AF= 80.72% | saved\n",
      "[21/25] 08219  | windows=  7363 | AF=  1640 ( 22.27%) | interval_AF= 21.59% | saved\n",
      "[22/25] 08378  | windows=  7363 | AF=  1858 ( 25.23%) | interval_AF= 25.12% | saved\n",
      "[23/25] 08405  | windows=  7363 | AF=  5319 ( 72.24%) | interval_AF= 72.21% | saved\n",
      "[24/25] 08434  | windows=  7363 | AF=   288 (  3.91%) | interval_AF=  3.87% | saved\n",
      "[25/25] 08455  | windows=  7363 | AF=  5095 ( 69.20%) | interval_AF= 69.17% | saved\n",
      "\n",
      "============================================================\n",
      "Summary CSV saved: ../artifacts/afdb_npz/summary.csv\n",
      "============================================================\n",
      "\n",
      "Processing Summary:\n",
      "  Total records found:        25\n",
      "  Successfully processed:     23\n",
      "  Failed:                     2\n",
      "  Records with both classes:  21\n",
      "\n",
      "Dataset Statistics:\n",
      "  Total windows:        168,645\n",
      "  Total AF windows:     68,799\n",
      "  Total Normal windows: 99,846\n",
      "  Overall AF%:          40.80%\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#main loop::\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AFDB Preprocessing Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Data directory:   {DATA_DIR}\")\n",
    "print(f\"Output directory: {OUT_DIR}\")\n",
    "print(f\"Window: {WIN_SEC}s | Stride: {STRIDE_SEC}s | AF threshold: {AF_THRESHOLD}\")\n",
    "print(f\"Filter: {LOW_HZ}-{HIGH_HZ} Hz | order={F_ORDER}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "records = listafdbrecords(DATA_DIR)\n",
    "print(f\"\\nFound {len(records)} records\")\n",
    "print(\"First 10:\", records[:10])\n",
    "\n",
    "summary_rows = []\n",
    "example_plotted = False\n",
    "\n",
    "for i, rid in enumerate(records, start=1):\n",
    "    try:\n",
    "        stats, Xn, y = process_one_record(rid)\n",
    "        summary_rows.append(stats)\n",
    "\n",
    "        print(\n",
    "            f\"[{i:02d}/{len(records)}] {rid:6s} | \"\n",
    "            f\"windows={stats['windows']:6d} | \"\n",
    "            f\"AF={stats['af_windows']:6d} ({100 * stats['af_pct_windows']:6.2f}%) | \"\n",
    "            f\"interval_AF={100 * stats['af_pct_intervals']:6.2f}% | saved\"\n",
    "        )\n",
    "\n",
    "        # Optional plot: first record that has both classes\n",
    "        if PLOT_EXAMPLES and (not example_plotted) and stats[\"has_both_classes\"]:\n",
    "            print(f\"\\nPlotting example windows from {rid}:\")\n",
    "            #plot_random_windows(Xn, y, k=PLOT_K, seed=PLOT_SEED, title_prefix=f\"{rid}: \")\n",
    "            example_plotted = True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{i:02d}/{len(records)}] {rid:6s} | SKIP: {e}\")\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"record\": rid,\n",
    "            \"fs\": np.nan,\n",
    "            \"samples\": np.nan,\n",
    "            \"win_len\": np.nan,\n",
    "            \"stride\": np.nan,\n",
    "            \"windows\": 0,\n",
    "            \"af_windows\": 0,\n",
    "            \"normal_windows\": 0,\n",
    "            \"af_pct_windows\": np.nan,\n",
    "            \"af_pct_intervals\": np.nan,\n",
    "            \"npz_path\": \"\",\n",
    "            \"has_both_classes\": False,\n",
    "            \"error\": str(e),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(summary_rows)\n",
    "df.to_csv(SUMMARY_CSV, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Summary CSV saved: {SUMMARY_CSV}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ok = df[df[\"npz_path\"] != \"\"]\n",
    "usable = ok[ok[\"has_both_classes\"]]\n",
    "\n",
    "print(\"\\nProcessing Summary:\")\n",
    "print(f\"  Total records found:        {len(records)}\")\n",
    "print(f\"  Successfully processed:     {len(ok)}\")\n",
    "print(f\"  Failed:                     {len(records) - len(ok)}\")\n",
    "print(f\"  Records with both classes:  {len(usable)}\")\n",
    "\n",
    "if len(ok) > 0 and ok[\"windows\"].sum() > 0:\n",
    "    total_w = int(ok[\"windows\"].sum())\n",
    "    total_af = int(ok[\"af_windows\"].sum())\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(f\"  Total windows:        {total_w:,}\")\n",
    "    print(f\"  Total AF windows:     {total_af:,}\")\n",
    "    print(f\"  Total Normal windows: {total_w - total_af:,}\")\n",
    "    print(f\"  Overall AF%:          {100 * total_af / total_w:.2f}%\")\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1b9d0e",
   "metadata": {},
   "source": [
    "*RR interval*\n",
    "    RR interval = time between two consecutive R-peaks in the ECG.\n",
    "    Measured in seconds.\n",
    "    If heartbeats are regular → RR intervals are similar.\n",
    "    If rhythm is irregular (like atrial fibrillation) → RR intervals vary a lot.\n",
    "\n",
    "HRV (Heart Rate Variability)\n",
    "    HRV = statistics computed from a sequence of RR intervals.\n",
    "    Why HRV matters for AF:\n",
    "    AF is characterized by irregularly irregular ventricular response.\n",
    "    HRV features capture this irregularity even when waveform shape looks normal.\n",
    "\n",
    "rr_feat is a 10-dimensional feature vector per window, computed from RR intervals inside that window.\n",
    "\n",
    "rr_valid is a binary flag per window:\n",
    "    rr_valid == 1 → RR features are reliable\n",
    "    rr_valid == 0 → RR features are unreliable / missing\n",
    "\n",
    "    Without rr_valid:\n",
    "    Zeroed RR features would look like meaningful low values\n",
    "    Model might learn wrong correlations\n",
    "    With rr_valid:\n",
    "    Model learns:\n",
    "    “If RR is invalid, ignore those features”\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
